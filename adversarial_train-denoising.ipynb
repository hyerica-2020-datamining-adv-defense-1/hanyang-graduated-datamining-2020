{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPUS = [0]\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, GPUS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import optimizers, metrics, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adversarial.attacks import random_attack\n",
    "from adversarial.utils import dataloader\n",
    "from adversarial.defences import EnsembleModel\n",
    "from adversarial import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPSILONS = np.arange(0.01, 0.5, step=0.02)\n",
    "ETA = 1e-4\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dloader = dataloader.DataLoader(\"data\", BATCH_SIZE, training=True)\n",
    "test_dloader = dataloader.DataLoader(\"data\", BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = models.TargetModel()\n",
    "target_model.load_custom_weights_for_mobilenet(\"model/model_20200507_9_1.00_0.0088\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = EnsembleModel([\n",
    "    models.MobileNetV2,\n",
    "    models.MobileNet,\n",
    "    models.VGG16,\n",
    "    models.VGG19,\n",
    "    models.ResNet50,\n",
    "    models.ResNet50V2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_losses = metrics.SparseCategoricalCrossentropy()\n",
    "train_metrics = metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "test_losses = metrics.SparseCategoricalCrossentropy()\n",
    "test_metrics = metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=ETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, labels, adv_labels):\n",
    "    adv, _, success = random_attack(ensemble_model, images, adv_labels, EPSILONS)\n",
    "    \n",
    "    \n",
    "    n = tf.shape(adv)[0]\n",
    "    slicing = tf.concat([tf.ones((n,), dtype=tf.int32), tf.cast(success, tf.int32)], axis=0)\n",
    "    \n",
    "    x_batch, y_batch = dataloader.concat_data(images, labels, adv)\n",
    "    x_batch = x_batch[slicing == 1]\n",
    "    y_batch = y_batch[slicing == 1]\n",
    "    \n",
    "#     for i in range(tf.shape(x_batch)[0]):\n",
    "#         print(y_batch[i].numpy())\n",
    "#         plt.imshow(x_batch.numpy()[i])\n",
    "#         plt.show()\n",
    "        \n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs, _ = target_model(x_batch, training=True)\n",
    "        loss = criterion(y_batch, outputs)\n",
    "        \n",
    "    train_losses.update_state(y_batch, outputs)\n",
    "    train_metrics.update_state(y_batch, outputs)\n",
    "        \n",
    "    grads = tape.gradient(loss, target_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, target_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(images, labels, adv_labels):\n",
    "    adv, _, success = random_attack(ensemble_model, images, adv_labels, EPSILONS)\n",
    "    \n",
    "    n = tf.shape(adv)[0]\n",
    "    slicing = tf.concat([tf.ones((n,), dtype=tf.int32), tf.cast(success, tf.int32)], axis=0)\n",
    "    \n",
    "    x_batch, y_batch = dataloader.concat_data(images, labels, adv)\n",
    "    x_batch = x_batch[slicing == 1]\n",
    "    y_batch = y_batch[slicing == 1]\n",
    "\n",
    "    outputs, _ = target_model(x_batch, training=False)\n",
    "\n",
    "    test_losses.update_state(y_batch, outputs)\n",
    "    test_metrics.update_state(y_batch, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    \n",
    "    best_test_loss = 1.0\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "        for x_batch, y_batch, adv_batch in iter(train_dloader):\n",
    "            train_step(x_batch, y_batch, adv_batch)\n",
    "\n",
    "        for x_batch, y_batch, adv_batch in iter(test_dloader):\n",
    "            test_step(x_batch, y_batch, adv_batch)\n",
    "\n",
    "        train_loss = train_losses.result()\n",
    "        train_acc = train_metrics.result()\n",
    "\n",
    "        test_loss = test_losses.result()\n",
    "        test_acc = test_metrics.result()\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "\n",
    "        train_losses.reset_states()\n",
    "        train_metrics.reset_states()\n",
    "        test_losses.reset_states()\n",
    "        test_metrics.reset_states()\n",
    "\n",
    "        print(f\"Epochs {e+1}/{EPOCHS}, train loss: {train_loss:.8f}, train acc: {train_acc:.4f}, test loss: {test_loss:.8f}, test acc: {test_acc:.4f}\")\n",
    "        \n",
    "        if best_test_loss >= test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            target_model.save_custom_weights(f\"model/ensemble_denoising-{now}.pkl\")\n",
    "        \n",
    "    return train_loss_list, test_loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jylee/miniconda3/envs/tf2/lib/python3.7/site-packages/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Epochs 1/30, train loss: 0.45553976, train acc: 0.8685, test loss: 0.68773121, test acc: 0.8320\n",
      "Epochs 2/30, train loss: 0.32827544, train acc: 0.8951, test loss: 0.73945963, test acc: 0.8193\n",
      "Epochs 3/30, train loss: 0.29181796, train acc: 0.9080, test loss: 0.72667569, test acc: 0.8722\n",
      "Epochs 4/30, train loss: 0.29071176, train acc: 0.9059, test loss: 0.78561556, test acc: 0.8205\n",
      "Epochs 5/30, train loss: 0.28742069, train acc: 0.9082, test loss: 0.68746173, test acc: 0.8349\n",
      "Epochs 6/30, train loss: 0.27721882, train acc: 0.9138, test loss: 0.62360686, test acc: 0.8417\n",
      "Epochs 7/30, train loss: 0.27611762, train acc: 0.9122, test loss: 0.61586708, test acc: 0.8449\n",
      "Epochs 8/30, train loss: 0.27348956, train acc: 0.9121, test loss: 0.94508946, test acc: 0.8118\n",
      "Epochs 9/30, train loss: 0.26502502, train acc: 0.9156, test loss: 0.86633426, test acc: 0.7919\n",
      "Epochs 10/30, train loss: 0.25907007, train acc: 0.9161, test loss: 1.03301525, test acc: 0.8201\n",
      "Epochs 11/30, train loss: 0.27935988, train acc: 0.9112, test loss: 1.21775401, test acc: 0.7567\n",
      "Epochs 12/30, train loss: 0.25482994, train acc: 0.9170, test loss: 0.63153189, test acc: 0.8393\n",
      "Epochs 13/30, train loss: 0.26350391, train acc: 0.9167, test loss: 0.59100711, test acc: 0.8485\n",
      "Epochs 14/30, train loss: 0.23328388, train acc: 0.9272, test loss: 0.79126406, test acc: 0.7941\n",
      "Epochs 15/30, train loss: 0.23987330, train acc: 0.9227, test loss: 0.69872308, test acc: 0.8036\n",
      "Epochs 16/30, train loss: 0.24372892, train acc: 0.9199, test loss: 0.59439564, test acc: 0.8428\n",
      "Epochs 17/30, train loss: 0.26687509, train acc: 0.9129, test loss: 0.60747892, test acc: 0.8345\n",
      "Epochs 18/30, train loss: 0.22480288, train acc: 0.9285, test loss: 0.58129680, test acc: 0.8426\n",
      "Epochs 19/30, train loss: 0.23169583, train acc: 0.9254, test loss: 0.78775567, test acc: 0.7933\n",
      "Epochs 20/30, train loss: 0.22699846, train acc: 0.9251, test loss: 0.66305280, test acc: 0.7972\n",
      "Epochs 21/30, train loss: 0.23258060, train acc: 0.9235, test loss: 0.79247439, test acc: 0.7938\n",
      "Epochs 22/30, train loss: 0.23205042, train acc: 0.9228, test loss: 0.62757325, test acc: 0.8187\n",
      "Epochs 23/30, train loss: 0.23888877, train acc: 0.9227, test loss: 0.71154076, test acc: 0.8235\n",
      "Epochs 24/30, train loss: 0.22929132, train acc: 0.9245, test loss: 0.59961724, test acc: 0.8308\n",
      "Epochs 25/30, train loss: 0.23560064, train acc: 0.9223, test loss: 0.54771751, test acc: 0.8488\n",
      "Epochs 26/30, train loss: 0.24067605, train acc: 0.9205, test loss: 0.58113146, test acc: 0.8303\n",
      "Epochs 27/30, train loss: 0.23924792, train acc: 0.9210, test loss: 0.98779494, test acc: 0.7795\n",
      "Epochs 28/30, train loss: 0.23746958, train acc: 0.9226, test loss: 0.60861093, test acc: 0.8184\n",
      "Epochs 29/30, train loss: 0.22904335, train acc: 0.9225, test loss: 0.80120748, test acc: 0.8020\n",
      "Epochs 30/30, train loss: 0.23161684, train acc: 0.9241, test loss: 0.82457131, test acc: 0.7842\n"
     ]
    }
   ],
   "source": [
    "train_loss_list, test_loss_list = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (Tensorflow 2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
