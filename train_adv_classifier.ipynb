{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adversarial.defences.adv_classifier import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "from adversarial.utils import dataloader\n",
    "from adversarial.attacks import random_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPSILONS = np.arange(0.01, 0.5, step=0.02)\n",
    "ETA = 1e-5\n",
    "EPOCHS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = dataloader.DataLoader('./data', 16, training=True)\n",
    "test_data_loader = dataloader.DataLoader('./data', 16, training= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adversarial.defences import EnsembleModel\n",
    "from adversarial.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_attack(앙상블 모델 넣을건데, x_image, adversarial_label, epsilon은 배열로)  \n",
    "epsilon = np.arange(0.01,0.5,0.02)  \n",
    "random_attack은 adversarial image를 리턴해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = AdvClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "criterion = losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = ETA)\n",
    "\n",
    "train_losses = tf.keras.metrics.CategoricalCrossentropy()\n",
    "train_metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "test_losses = tf.keras.metrics.CategoricalCrossentropy()\n",
    "test_metrics = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = EnsembleModel([\n",
    "    VGG19, VGG16, MobileNet, MobileNetV2, ResNet50, ResNet50V2\n",
    "], devices = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[0,1] ,[1,0]]\n",
    "    \n",
    "y_batch = []\n",
    "    \n",
    "    \n",
    "for label in labels : \n",
    "    for time in range(16) :\n",
    "        y_batch.append(label)\n",
    "\n",
    "y_tensor = tf.convert_to_tensor(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, adv_labels):\n",
    "\n",
    "    adv, _, success = random_attack(ensemble_model, images, adv_labels, EPSILONS)\n",
    "    \n",
    "    x_batch = tf.concat([images, adv], axis=0)\n",
    "    y_batch = y_tensor\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = target_model(x_batch, training = True)\n",
    "      #  print('y_batch : ' ,y_batch)\n",
    "       # print('outputs : ' ,outputs)\n",
    "        loss = criterion(y_batch, outputs)\n",
    "    #print(loss.numpy())\n",
    "    train_losses.update_state(y_batch, outputs)\n",
    "    train_metrics.update_state(y_batch, outputs)\n",
    "        \n",
    "    grads = tape.gradient(loss, target_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, target_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(images, labels, adv_labels) :\n",
    "    adv,_, success = random_attack(ensemble_model, images, adv_labels, EPSILONS)\n",
    "    x_batch = tf.concat([images, adv], axis=0)\n",
    "    y_batch = y_tensor\n",
    "    #y_batch = tf.concat([tf.zeros(16, dtype = tf.int32),\n",
    "     #                    tf.ones(16, dtype = tf.int32)], \n",
    "      #                   axis = 0)\n",
    "    \n",
    "    predictions = target_model(x_batch, training= False)\n",
    "    loss = tf.keras.losses.binary_crossentropy(y_batch, predictions)\n",
    "    test_losses.update_state(y_batch, predictions)\n",
    "    test_metrics.update_state(y_batch, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "        for x_batch, y_batch, adv_batch in tqdm(iter(train_data_loader)):\n",
    "            train_step(x_batch, adv_batch)\n",
    "\n",
    "        for x_batch, y_batch, adv_batch in tqdm(iter(test_data_loader)):\n",
    "            test_step(x_batch, y_batch, adv_batch)\n",
    "\n",
    "\n",
    "        train_loss = train_losses.result()\n",
    "        train_acc = train_metrics.result()\n",
    "\n",
    "        test_loss = test_losses.result()\n",
    "        test_acc = test_metrics.result()\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "\n",
    "        train_losses.reset_states()\n",
    "        train_metrics.reset_states()\n",
    "        test_losses.reset_states()\n",
    "        test_metrics.reset_states()\n",
    "        \n",
    "        print(f\"Epochs {e+1}/{EPOCHS}, train loss: {train_loss:.8f}, train acc: {train_acc:.4f}, test loss: {test_loss:.8f}, test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_weights(target, path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        target.load_weights(data)\n",
    "\n",
    "def save_custom_weights(target, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(target.get_weights(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rhsl1996/anaconda3/envs/datamining/lib/python3.8/site-packages/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [31:25,  2.34s/it]\n",
      "32it [00:48,  1.52s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1/6, train loss: 0.62572742, train acc: 0.6074, test loss: 0.58062869, test acc: 0.6621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [33:13,  2.47s/it]\n",
      "32it [02:28,  4.63s/it]\n",
      "1it [00:00,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 2/6, train loss: 0.57831603, train acc: 0.6571, test loss: 0.59902668, test acc: 0.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [35:51,  2.67s/it]\n",
      "32it [01:19,  2.48s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 3/6, train loss: 0.57296580, train acc: 0.6609, test loss: 0.52590334, test acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [32:18,  2.41s/it]\n",
      "32it [01:01,  1.91s/it]\n",
      "1it [00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 4/6, train loss: 0.56420678, train acc: 0.6711, test loss: 0.56936163, test acc: 0.6621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [30:09,  2.24s/it]\n",
      "32it [01:23,  2.59s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 5/6, train loss: 0.57220560, train acc: 0.6616, test loss: 0.52034312, test acc: 0.7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [36:15,  2.70s/it]\n",
      "32it [01:54,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 6/6, train loss: 0.56949013, train acc: 0.6617, test loss: 0.57741475, test acc: 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_custom_weights(target_model, './adv_classifier_BN_6.4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [32:47,  2.44s/it]\n",
      "32it [01:22,  2.58s/it]\n",
      "1it [00:00,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1/6, train loss: 0.56903332, train acc: 0.6626, test loss: 0.54330730, test acc: 0.6982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [32:23,  2.41s/it]\n",
      "32it [00:55,  1.73s/it]\n",
      "1it [00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 2/6, train loss: 0.55978245, train acc: 0.6762, test loss: 0.59399581, test acc: 0.6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266it [12:00,  2.42s/it]"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
