{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adversarial.attacks import random_attack\n",
    "from adversarial.utils import dataloader\n",
    "from adversarial.defences import EnsembleModel\n",
    "from adversarial import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, metrics, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPSILONS = np.arange(0.01, 0.5, step=0.02)\n",
    "ETA = 1e-6\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dloader = dataloader.DataLoader(\"data\", BATCH_SIZE, training=True)\n",
    "test_dloader = dataloader.DataLoader(\"data\", BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = models.TargetModel()\n",
    "target_model.load_custom_weights_for_mobilenet(\"model/model_20200507_9_1.00_0.0088\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = EnsembleModel([\n",
    "    models.MobileNetV2(),\n",
    "    models.MobileNet(),\n",
    "    models.VGG16(),\n",
    "    models.VGG19(),\n",
    "    models.ResNet50(),\n",
    "    models.ResNet50V2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_losses = metrics.SparseCategoricalCrossentropy()\n",
    "train_metrics = metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "test_losses = metrics.SparseCategoricalCrossentropy()\n",
    "test_metrics = metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=ETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, labels, adv_labels):\n",
    "    adv, _, success = random_attack(ensemble_model, images, adv_labels, EPSILONS)\n",
    "    \n",
    "    x_batch, y_batch = dataloader.concat_data(images, labels, adv)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = target_model(x_batch, training=True)\n",
    "        loss = criterion(y_batch, outputs)\n",
    "        \n",
    "    train_losses.update_state(y_batch, outputs)\n",
    "    train_metrics.update_state(y_batch, outputs)\n",
    "        \n",
    "    grads = tape.gradient(loss, target_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, target_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(images, labels, adv_labels):\n",
    "    adv, _, success = random_attack(ensemble_model, images, adv_labels, EPSILONS)\n",
    "    \n",
    "    x_batch, y_batch = dataloader.concat_data(images, labels, adv)\n",
    "\n",
    "    outputs = target_model(x_batch, training=False)\n",
    "\n",
    "    test_losses.update_state(y_batch, outputs)\n",
    "    test_metrics.update_state(y_batch, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "        for x_batch, y_batch, adv_batch in iter(train_dloader):\n",
    "            train_step(x_batch, y_batch, adv_batch)\n",
    "\n",
    "        for x_batch, y_batch, adv_batch in iter(test_dloader):\n",
    "            test_step(x_batch, y_batch, adv_batch)\n",
    "\n",
    "        train_loss = train_losses.result()\n",
    "        train_acc = train_metrics.result()\n",
    "\n",
    "        test_loss = test_losses.result()\n",
    "        test_acc = test_losses.result()\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "\n",
    "        train_loss.reset_states()\n",
    "        train_acc.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_acc.reset_states()\n",
    "\n",
    "        print(f\"Epochs {e+1}/{EPOCHS}, train loss: {train_loss:.8f}, train acc: {train_acc:.4f}, test loss: {test_loss:.8f}, test acc: {test_acc:.4f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}